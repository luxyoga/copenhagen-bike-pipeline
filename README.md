# Copenhagen Bike Data Pipeline (Airflow + PySpark)

End-to-end pipeline to ingest Copenhagen bike counter & weather data, transform it into **Bronze / Silver / Gold layers**, orchestrate with **Airflow**, and visualize results with **Streamlit**.

---

## ğŸš´ Project Overview
This project demonstrates modern **data engineering workflows**:
- **Ingestion**: fetch Copenhagen open bike counter data + weather API
- **Storage**: organize raw â†’ clean â†’ aggregated datasets (Bronze/Silver/Gold)
- **Processing**: transform with **PySpark**
- **Orchestration**: schedule pipelines with **Airflow**
- **Visualization**: Streamlit dashboard for interactive insights

---

## âš™ï¸ Tech Stack
- **Python** for ingestion & scripting  
- **PySpark** for distributed data transformations  
- **Airflow** for orchestration & scheduling  
- **DuckDB / Parquet** for local storage and querying  
- **Streamlit** for dashboard visualization  
- **GitHub Actions** (future) for automation  

---

## ğŸš€ Quickstart

### 1) Clone the repository
```bash
git clone https://github.com/luxyoga/copenhagen-bike-pipeline.git
cd copenhagen-bike-pipeline
